{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1231f25-3d76-4e6f-a97b-974afa1c1775",
   "metadata": {},
   "source": [
    "## inear Regression이란? ##\n",
    "<p>입력 변수 𝑋와 출력 변수 𝑦 사이의 관계를 직선 형태로 모델링하는 방법</p>\n",
    "<p> y = w1x1 + w2x2 + ... wnxn + b</p> \n",
    "    \n",
    "    -wi: 각 특성의 기울기 -> coef_\n",
    "    -b: y절편 -> intercept_\n",
    "    \n",
    "\n",
    "#### 주요 파라미터 ####\n",
    "<p>LinearRegression(fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None)</p>\n",
    "\n",
    "    - fit_intercept: 절편 b를 학습할지 여부 (기본: True)\n",
    "    - copy_X: 원본 X를 복사해서 쓸지 여부\n",
    "    - n_jobs: 계산에 사용할 CPU 수 (병렬처리)\n",
    "\n",
    "#### 주요 속성 (학습 후 사용) ####\n",
    "\n",
    "    -coef_: 각 특성의 계수 (기울기)\n",
    "    -intercept_: y절편\n",
    "    -score(X, y): 결정계수 R^2 : 모델의 설명력 평가 (1에 가까울수록 좋음)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220be610-4e37-4e78-ad84-77172701bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07f84ec-1b00-4124-90c8-c2d218acadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4)\n",
      "y (150,)\n",
      "X_train: (120, 4)\n",
      "y_train (120,)\n",
      "X_test (30, 4)\n",
      "y_test (30,)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "df = pd.DataFrame(iris.frame)\n",
    "\n",
    "X = df.drop('target', axis=True)\n",
    "y = df.target\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57890622-db5d-447d-95d4-67e2fb63778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [-0.11633479 -0.05977785  0.25491375  0.54759598]\n",
      "절편: 0.25252758981814694\n",
      "R2 점수: 0.9468960016420045\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", model.coef_)\n",
    "print(\"절편:\", model.intercept_)\n",
    "print(\"R2 점수:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b30339-90be-4358-b0a1-1fdba500a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 0.03711379440797688\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"mean_squared_error:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46bcae3-ca43-4a14-96a2-286e72c14017",
   "metadata": {},
   "source": [
    "## Ridge Regression & Ridge Classification ##\n",
    "선형 회귀/분류 모델에서 과적합(overfitting)을 줄이기 위해 고안된 정규화(regularization) 기법  \n",
    "가중치(w)의 크기를 너무 크게 하지 않도록 제어\n",
    "\n",
    "\n",
    "### Ridge Regression ###\n",
    "📌 기본 선형 회귀는 다음을 최소화:  \n",
    "    <span style=\"font-size:16px\">Loss = ∑(y - y_)^2<span>\n",
    "\n",
    "Ridge는 여기에 규제 항 (penalty) 를 추가  \n",
    "    <span style=\"font-size:16px\">Ridge Loss = ∑(y - y_)^2 + λ∑(w)^2<span>\n",
    "\n",
    "    -다중공선성(피처 간 상관관계)에 강함\n",
    "\n",
    "    -예측이 더 안정적\n",
    "\n",
    "    -모든 피처를 사용하지만 계수를 작게 유지\n",
    "\n",
    "### Ridge Classification ###\n",
    "\n",
    "Ridge Classification은 Ridge 정규화를 적용한 로지스틱 회귀 기반 분류기  \n",
    "\n",
    "sklearn.linear_model.RidgeClassifier로 사용 가능  \n",
    "\n",
    "RidgeClassifier는 내부적으로 loss를 least squares 형태로 계산\n",
    "\n",
    "\n",
    "---\n",
    "y_ == y위에 모자 있는거  \n",
    "y: 실제 정답\n",
    "y_: 예측값 (wx + b)\n",
    "w: 각 피처(feature)에 해당하는 회귀 계수 (기울기) == coefficient (계수)\n",
    "λ: 정규화 강도 (hyperparameter, 사용자가 정함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2fda700-ddf1-4dce-a1ce-f6eb2cd427fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [-0.11850607 -0.05378752  0.27375879  0.50482122]\n",
      "절편: 0.2271881162576862\n",
      "R2 점수: 0.945398779823663\n"
     ]
    }
   ],
   "source": [
    "# regresion\n",
    "# Ridge 회귀기(Ridge Regressor)는 분류 버전도 있다: RidgeClassifier\n",
    "model2 = Ridge(alpha=0.5)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", model2.coef_)\n",
    "print(\"절편:\", model2.intercept_)\n",
    "print(\"R2 점수:\", model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b236f3-f0a7-44e5-954e-bca4071631a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 0.03816018610101772\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(\"mean_squared_error:\", mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
