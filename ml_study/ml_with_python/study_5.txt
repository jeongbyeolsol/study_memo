📌 k-겹 교차검증 (k-fold CV)

    1. 데이터를 k개로 균등하게 분할.
    2. 그중 1개를 검증(validation) 세트로 사용하고, 나머지 k−1개로 학습.
    3. 이 과정을 k번 반복해서, 각 분할마다 검증 성능을 측정.
    4. 마지막에 k개의 결과를 평균 내어 모델 성능으로 사용.
        예: k=5라면 → 학습:검증 = 4:1 비율로 총 5번 학습·평가.

    ✅ 장점
        데이터 효율적 사용 (훈련/검증 모두에 고르게 활용)
        모델 성능 평가가 더 안정적 (특히 데이터 적을 때)
    ❌ 단점
        계산량 많음 (모델 학습을 k번 반복해야 함)
        매우 큰 데이터셋에서는 비효율적일 수 있음

    “하이퍼파라미터 튜닝”과 “최종 성능 평가”는 분리된 데이터에서 해야 함 → Nested CV 또는 따로 최종 테스트셋 유지하기.
    데이터셋이 충분히 크면 굳이 k-fold 안 쓰고 train/val/test 3분할로도 충분.

구분        cross_val_score         cross_validate
반환 형태   점수 배열 (numpy array) 결과 딕셔너리
지원 스코어 단일 metric             여러 metric 가능
부가 정보   없음                    학습/예측 시간, 훈련 성능까지 포함
사용 용도   간단히 점수만 볼 때     여러 평가 지표/시간 포함해 상세 분석할 때


📌 KFold 클래스
    데이터를 K개의 연속된 덩어리(fold)로 나눈 다음, 각 fold를 검증 세트로 한 번씩 사용하면서 총 K번 학습·평가를 수행할 수 있게 해주는 도구
    즉, k-겹 교차검증(k-fold cross-validation)을 구현할 때 쓰는 클래스
    🛠️ 주요 매개변수
        KFold(n_splits=5, shuffle=False, random_state=None)
            n_splits: 몇 겹으로 나눌지 (기본=5)
            shuffle: 데이터를 나누기 전에 섞을지 여부 (기본=False)
            random_state: shuffle=True일 때 난수 고정

    주요 변형들
        Stratified k-fold
            분류 문제에서, 클래스 비율을 훈련/검증 데이터에 고르게 유지하도록 나누는 방식. (불균형 데이터에 필수)
        Leave-One-Out (LOO, == LOOCV)
            데이터 N개일 때, 매번 1개 샘플만 검증에 쓰고 나머지 N−1개로 학습. → 데이터가 매우 적을 때 사용.
        ShuffleSplit
            무작위로 훈련/검증을 반복 샘플링. k-fold처럼 균등 분할이 아니라 랜덤 추출.
        Nested CV
            모델 성능 평가와 하이퍼파라미터 튜닝을 동시에 할 때 쓰는 이중 루프 CV.
        GroupKFold
            은 그룹에 속한 샘플이 반드시 같은 fold 안에 들어가도록 나눠주는 방식
        RepeatedKFold, RepeatedStratifiedKFold
            기존 교차검증(KFold/StratifiedKFold)을 여러 번 반복해서 더 안정적인 평가를 얻기 위한 클래스
            여러 번 반복해서 데이터를 다시 섞고, 각기 다른 분할 결과


📌 그리드 서치(Grid Search) 개념
    1. 여러 하이퍼파라미터 후보 값을 격자(grid) 형태로 나열
    2. 가능한 모든 조합에 대해 교차검증(CV)으로 성능을 평가
    3. 가장 좋은 성능을 낸 조합을 선택

    ✅ 장점
        가장 직관적이고 구현이 간단
        모든 조합을 시도하므로 최적값을 놓칠 확률이 낮음
    ❌ 단점
        조합이 많아지면 계산량 폭발 (“차원의 저주”)
        연속적인 값은 다룰 수 없어 (예: learning_rate=0.01~1 사이) → 미리 후보를 정해야 함

    대안
        RandomizedSearchCV → 모든 조합이 아니라 랜덤 샘플링해서 탐색. 속도가 훨씬 빠름
        Bayesian Optimization, Hyperopt, Optuna → 과거 탐색 결과를 바탕으로 더 똑똑하게 후보를 정해서 탐색


